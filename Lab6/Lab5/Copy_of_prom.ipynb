{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XfPJby-2E_II"
      },
      "source": [
        "# Step 1: Install and Import Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CaAXOq7cFUCx"
      },
      "outputs": [],
      "source": [
        "# Get time series data\n",
        "#import yfinance as yf\n",
        "\n",
        "# Prophet model for time series forecast\n",
        "from prophet import Prophet\n",
        "\n",
        "# Data processing\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# Visualization\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Model performance evaluation\n",
        "from sklearn.metrics import mean_absolute_error, mean_absolute_percentage_error"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2S3-Wup8FVRK"
      },
      "source": [
        "# Step 2: Pull Data"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import pandas as pd\n",
        "import requests\n",
        "\n",
        "# Replace with your actual GitHub raw file URL\n",
        "# github_url = \"https://raw.githubusercontent.com/cfwiecha/Fall2024Capstone/refs/heads/main/frontend_shipping_source_300m_30s_pruned.json\"\n",
        "\n",
        "github_url = \"https://raw.githubusercontent.com/yuyunfrancis/aiops/refs/heads/master/Lab6/Lab5/boutique_training.json\"\n",
        "\n",
        "try:\n",
        "    response = requests.get(github_url)\n",
        "    response.raise_for_status()  # Raise an exception for bad status codes (4xx or 5xx)\n",
        "\n",
        "    data = response.json()\n",
        "    df_train = pd.DataFrame( data['data']['result'][0]['values'] )\n",
        "    df_train.columns = ['ds', 'y']\n",
        "    print( df_train.head() )\n",
        "\n",
        "except requests.exceptions.RequestException as e:\n",
        "    print(f\"Error fetching data from GitHub: {e}\")\n",
        "except ValueError as e:\n",
        "    print(f\"Error decoding JSON response: {e}\")\n",
        "except Exception as e:\n",
        "    print(f\"An unexpected error occurred: {e}\")"
      ],
      "metadata": {
        "id": "usryUP-CnfWe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_zq9BH2CnR3j"
      },
      "outputs": [],
      "source": [
        "import json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2yj7H4BAnR3j"
      },
      "outputs": [],
      "source": [
        "#f = open(\"frontend_shipping_source_300m_30s_pruned.json\")\n",
        "#prom = json.load(f)\n",
        "#df_train = pd.DataFrame( data['data']['result'][0]['values'] )\n",
        "#df_train.columns = ['ds', 'y']\n",
        "#df_train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EyqAGTUAnR3k"
      },
      "outputs": [],
      "source": [
        "# Replace with your actual GitHub raw file URL\n",
        "# github_url = \"https://raw.githubusercontent.com/cfwiecha/Fall2024Capstone/refs/heads/main/20min.json\"\n",
        "\n",
        "github_url = \"https://raw.githubusercontent.com/yuyunfrancis/aiops/refs/heads/master/Lab6/Lab5/boutique_training.json\"\n",
        "\n",
        "\n",
        "try:\n",
        "    response = requests.get(github_url)\n",
        "    response.raise_for_status()  # Raise an exception for bad status codes (4xx or 5xx)\n",
        "\n",
        "    data = response.json()\n",
        "    df_test = pd.DataFrame( data['data']['result'][0]['values'] )\n",
        "    df_test.columns = ['ds', 'y']\n",
        "    print( df_test.head() )\n",
        "\n",
        "except requests.exceptions.RequestException as e:\n",
        "    print(f\"Error fetching data from GitHub: {e}\")\n",
        "except ValueError as e:\n",
        "    print(f\"Error decoding JSON response: {e}\")\n",
        "except Exception as e:\n",
        "    print(f\"An unexpected error occurred: {e}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_test"
      ],
      "metadata": {
        "id": "ZiiCB3hbrW7z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p5V3t0pFnR3k"
      },
      "outputs": [],
      "source": [
        "#align test timestamps with training by time shifting back to the first train time...assume test data starts from 0 cycle time like training data\n",
        "\n",
        "train_start_ds = df_train['ds'].iloc[0]\n",
        "print(train_start_ds)\n",
        "\n",
        "df_train['ds'] = df_train['ds'] - train_start_ds\n",
        "\n",
        "df_train.head()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#align test timestamps with training by time shifting back to the first train time...assume test data starts from 0 cycle time like training data\n",
        "\n",
        "test_start_ds = df_test['ds'].iloc[0]\n",
        "print(test_start_ds)\n",
        "\n",
        "df_test['ds'] = df_test['ds'] - test_start_ds\n",
        "\n",
        "df_test.head()"
      ],
      "metadata": {
        "id": "V6VjYRHCrybM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "maKxHBJ2nR3l"
      },
      "outputs": [],
      "source": [
        "from datetime import datetime"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xiFKjmGrnR3l"
      },
      "outputs": [],
      "source": [
        "df_train['ds'] = df_train['ds'].apply(lambda sec: datetime.fromtimestamp(sec))\n",
        "df_train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sT03u_z1nR3l"
      },
      "outputs": [],
      "source": [
        "df_test['ds'] = df_test['ds'].apply(lambda sec: datetime.fromtimestamp(sec))\n",
        "df_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CEpEZAhJPpaV"
      },
      "outputs": [],
      "source": [
        "# Information on the dataframe\n",
        "df_train['y']=df_train['y'].astype(float)\n",
        "df_train.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HuxQE2M1nR3l"
      },
      "outputs": [],
      "source": [
        "# Information on the dataframe\n",
        "df_test['y']=df_test['y'].astype(float)\n",
        "df_test.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VinXfvMYnDna"
      },
      "source": [
        "Next, let's visualize the closing prices of the two tickers using `seaborn`, and add the legend to the plot using `matplotlib`. We can see that the price for Google increased a lot starting in late 2020, and almost doubled in late 2021."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NhKMo4c-oU_8"
      },
      "outputs": [],
      "source": [
        "# Visualize data using seaborn\n",
        "sns.set(rc={'figure.figsize':(12,8)})\n",
        "sns.lineplot(x=df_train['ds'], y=df_train['y'])\n",
        "plt.legend(['Training metric'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rv4D-_sSoVHx"
      },
      "source": [
        "# Step 3: Build Time Series Model Using Prophet in Python"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RZoayReeoYGu"
      },
      "outputs": [],
      "source": [
        "# Add seasonality\n",
        "model = Prophet(interval_width=0.99, yearly_seasonality=False, weekly_seasonality=False, daily_seasonality=False, growth='flat')\n",
        "model.add_seasonality(name='hourly', period=1/24, fourier_order=5)\n",
        "\n",
        "# Fit the model on the training dataset\n",
        "model.fit(df_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lbBJPgjlbX1p"
      },
      "source": [
        "# Step 4: Make Predictions Using Prophet in Python"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q5pt-y6vxg5C"
      },
      "source": [
        "After building the model, in step 4, we use the model to make predictions on the dataset. The forecast plot shows that the predictions are in general aligned with the actual values."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "idCZyhdexIJN",
        "scrolled": false
      },
      "outputs": [],
      "source": [
        "# Make prediction\n",
        "forecast = model.predict(df_test)\n",
        "\n",
        "# Visualize the forecast\n",
        "model.plot(forecast); # Add semi-colon to remove the duplicated chart"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ylnS1AkqyGyo"
      },
      "source": [
        "We can also check the components plot for the trend, weekly seasonality, and yearly seasonality."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8DMoBQnOzXX0"
      },
      "outputs": [],
      "source": [
        "# Visualize the forecast components\n",
        "model.plot_components(forecast);"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BLOvRvxmcKIc"
      },
      "source": [
        "# Step 5: Check Time Series Model Performace"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JHKAg6JGnR3m"
      },
      "outputs": [],
      "source": [
        "forecast"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xo8fY96enR3m"
      },
      "outputs": [],
      "source": [
        "# Merge actual and predicted values\n",
        "performance = pd.merge(df_test, forecast[['ds', 'yhat', 'yhat_lower', 'yhat_upper']], on='ds')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WHhXkJslnR3m"
      },
      "outputs": [],
      "source": [
        "performance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tjZCV1qenR3m"
      },
      "outputs": [],
      "source": [
        "performance.dropna(subset=['y', 'yhat'], inplace=True)\n",
        "\n",
        "# Check MAE value\n",
        "performance_MAE = mean_absolute_error(performance['y'], performance['yhat'])\n",
        "print(f'The MAE for the model is {performance_MAE}')\n",
        "\n",
        "# Check MAPE value\n",
        "performance_MAPE = mean_absolute_percentage_error(performance['y'], performance['yhat'])\n",
        "print(f'The MAPE for the model is {performance_MAPE}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "liM3SW227N-b"
      },
      "source": [
        "# Step 6: Identify Anomalies"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d3lS7hpdnGqp"
      },
      "source": [
        "In step 6, we will identify the time series anomalies by checking if the actual value is outside of the uncertainty interval. If the actual value is smaller than the lower bound or larger than the upper bound of the uncertainty interval, the anomaly indicator is set to 1, otherwise, it's set to 0.\n",
        "\n",
        "Using `value_counts()`, we can see that there are 6 outliers out of 505 data points."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BmchMZp77S7-"
      },
      "outputs": [],
      "source": [
        "# Create an anomaly indicator\n",
        "performance['anomaly'] = performance.apply(lambda rows: 1 if ((float(rows.y)<rows.yhat_lower)|(float(rows.y)>rows.yhat_upper)) else 0, axis = 1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HNEasRwmnR3n"
      },
      "outputs": [],
      "source": [
        "performance.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AmlsjQLlnR3n"
      },
      "outputs": [],
      "source": [
        "# Check the number of anomalies\n",
        "performance['anomaly'].value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RADSkUwPoNnm"
      },
      "source": [
        "After printing out the anomalies, we can see that all the outliers are lower than the lower bound of the uncertainty interval."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IbiUpzv979Qd"
      },
      "outputs": [],
      "source": [
        "# Take a look at the anomalies\n",
        "anomalies = performance[performance['anomaly']==1].sort_values(by='ds')\n",
        "anomalies"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Un2KsjHovfj"
      },
      "source": [
        "In the visualization, all the dots are actual values and the black line represents the predicted values. The orange dots are the outliers."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gGucpnRu8GAS"
      },
      "outputs": [],
      "source": [
        "# Visualize the anomalies\n",
        "sns.scatterplot(x='ds', y='y', data=performance, hue='anomaly')\n",
        "sns.lineplot(x='ds', y='yhat', data=performance, color='black')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7nv18iH9nR3n"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.16"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}